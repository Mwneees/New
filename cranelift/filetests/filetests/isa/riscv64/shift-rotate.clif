test compile precise-output
set unwind_info=false
target riscv64

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; ROR, variable
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

function %i128_rotr(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = rotr.i128 v0, v1
  return v2
}

; block0:
;   andi a7,a2,63
;   ori t4,zero,64
;   sub t4,t4,a7
;   srl t2,a0,a7
;   sll a3,a1,t4
;   select_reg a3,zero,a3;;condition=(a7 eq zero) 
;   or t2,t2,a3
;   srl a5,a1,a7
;   sll t3,a0,t4
;   select_reg t3,zero,t3;;condition=(a7 eq zero) 
;   or a5,a5,t3
;   ori t1,zero,64
;   andi a1,a2,127
;   select_reg a0,t2,a5;;condition=(a1 ult t1) 
;   select_reg a1,a5,t2;;condition=(a1 ult t1) 
;   ret

function %f0(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = rotr.i64 v0, v1
  return v2
}

; block0:
;   ror a0,a0,a1
;   ret

function %f1(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = rotr.i32 v0, v1
  return v2
}

; block0:
;   rorw a0,a0,a1
;   ret

function %f2(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = rotr.i16 v0, v1
  return v2
}

; block0:
;   mov t0,a0
;   andi a3,a1,15
;   ori a5,zero,16
;   sub a5,a5,a3
;   srl a0,t0,a3
;   sll t4,t0,a5
;   or a0,a0,t4
;   ret

function %f3(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = rotr.i8 v0, v1
  return v2
}

; block0:
;   mov t0,a0
;   andi a3,a1,7
;   ori a5,zero,8
;   sub a5,a5,a3
;   srl a0,t0,a3
;   sll t4,t0,a5
;   or a0,a0,t4
;   ret

function %i128_rotl(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = rotl.i128 v0, v1
  return v2
}

; block0:
;   andi a7,a2,63
;   ori t4,zero,64
;   sub t4,t4,a7
;   sll t2,a0,a7
;   srl a3,a1,t4
;   select_reg a3,zero,a3;;condition=(a7 eq zero) 
;   or t2,t2,a3
;   sll a5,a1,a7
;   srl t3,a0,t4
;   select_reg t3,zero,t3;;condition=(a7 eq zero) 
;   or a5,a5,t3
;   ori t1,zero,64
;   andi a1,a2,127
;   select_reg a0,t2,a5;;condition=(a1 ult t1) 
;   select_reg a1,a5,t2;;condition=(a1 ult t1) 
;   ret

function %f4(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = rotl.i64 v0, v1
  return v2
}

; block0:
;   rol a0,a0,a1
;   ret

function %f5(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = rotl.i32 v0, v1
  return v2
}

; block0:
;   rolw a0,a0,a1
;   ret

function %f6(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = rotl.i16 v0, v1
  return v2
}

; block0:
;   mov t0,a0
;   andi a3,a1,15
;   ori a5,zero,16
;   sub a5,a5,a3
;   sll a0,t0,a3
;   srl t4,t0,a5
;   or a0,a0,t4
;   ret

function %f7(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = rotl.i8 v0, v1
  return v2
}

; block0:
;   mov t0,a0
;   andi a3,a1,7
;   ori a5,zero,8
;   sub a5,a5,a3
;   sll a0,t0,a3
;   srl t4,t0,a5
;   or a0,a0,t4
;   ret

function %f8(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = ushr.i64 v0, v1
  return v2
}

; block0:
;   srl a0,a0,a1
;   ret

function %f9(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = ushr.i32 v0, v1
  return v2
}

; block0:
;   srlw a0,a0,a1
;   ret

function %f10(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = ushr.i16 v0, v1
  return v2
}

; block0:
;   srlw a0,a0,a1
;   ret

function %f11(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = ushr.i8 v0, v1
  return v2
}

; block0:
;   srlw a0,a0,a1
;   ret

function %f12(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = ishl.i64 v0, v1
  return v2
}

; block0:
;   sll a0,a0,a1
;   ret

function %f13(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = ishl.i32 v0, v1
  return v2
}

; block0:
;   sllw a0,a0,a1
;   ret

function %f14(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = ishl.i16 v0, v1
  return v2
}

; block0:
;   sllw a0,a0,a1
;   ret

function %f15(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = ishl.i8 v0, v1
  return v2
}

; block0:
;   sllw a0,a0,a1
;   ret

function %f16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sshr.i64 v0, v1
  return v2
}

; block0:
;   sra a0,a0,a1
;   ret

function %f17(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = sshr.i32 v0, v1
  return v2
}

; block0:
;   sraw a0,a0,a1
;   ret

function %f18(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = sshr.i16 v0, v1
  return v2
}

; block0:
;   sraw a0,a0,a1
;   ret

function %f19(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = sshr.i8 v0, v1
  return v2
}

; block0:
;   sraw a0,a0,a1
;   ret

function %f20(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i32 17
  v2 = rotr.i64 v0, v1
  return v2
}

; block0:
;   ori a1,zero,17
;   ror a0,a0,a1
;   ret

function %f21(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i32 17
  v2 = rotl.i64 v0, v1
  return v2
}

; block0:
;   ori a1,zero,17
;   rol a0,a0,a1
;   ret

function %f22(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 17
  v2 = rotl.i32 v0, v1
  return v2
}

; block0:
;   ori a1,zero,17
;   rolw a0,a0,a1
;   ret

function %f23(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i32 10
  v2 = rotl.i16 v0, v1
  return v2
}

; block0:
;   mov t0,a0
;   ori a0,zero,10
;   andi a3,a0,15
;   ori a5,zero,16
;   sub a5,a5,a3
;   sll a0,t0,a3
;   srl t4,t0,a5
;   or a0,a0,t4
;   ret

function %f24(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i32 3
  v2 = rotl.i8 v0, v1
  return v2
}

; block0:
;   mov t0,a0
;   ori a0,zero,3
;   andi a3,a0,7
;   ori a5,zero,8
;   sub a5,a5,a3
;   sll a0,t0,a3
;   srl t4,t0,a5
;   or a0,a0,t4
;   ret

function %f25(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i32 17
  v2 = ushr.i64 v0, v1
  return v2
}

; block0:
;   srli a0,a0,17
;   ret

function %f26(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i32 17
  v2 = sshr.i64 v0, v1
  return v2
}

; block0:
;   srli a0,a0,17
;   ret

function %f27(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i32 17
  v2 = ishl.i64 v0, v1
  return v2
}

; block0:
;   slli a0,a0,17
;   ret

