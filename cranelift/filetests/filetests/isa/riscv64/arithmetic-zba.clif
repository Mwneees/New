test compile precise-output
set unwind_info=false
target riscv64 has_zba


function %add_uw_i8(i64, i8) -> i64 {
block0(v0: i64, v1: i8):
    v2 = uextend.i64 v1
    v3 = iadd.i64 v0, v2
    return v3
}

; VCode:
; block0:
;   add.uw a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x3b, 0x05, 0xb5, 0x08
;   ret

function %add_uw_i16(i64, i16) -> i64 {
block0(v0: i64, v1: i16):
    v2 = uextend.i64 v1
    v3 = iadd.i64 v0, v2
    return v3
}

; VCode:
; block0:
;   add.uw a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x3b, 0x05, 0xb5, 0x08
;   ret

function %add_uw_i32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
    v2 = uextend.i64 v1
    v3 = iadd.i64 v0, v2
    return v3
}

; VCode:
; block0:
;   add.uw a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x3b, 0x05, 0xb5, 0x08
;   ret

function %sh1add(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 1
    v3 = ishl v1, v2
    v4 = iadd.i64 v0, v3
    return v4
}

; VCode:
; block0:
;   slli a1,a1,1
;   add a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a1, a1, 1
;   add a0, a0, a1
;   ret

;; Same as %sh1add but with the operands reversed
function %sh1add_r(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 1
    v3 = ishl v1, v2
    v4 = iadd.i64 v3, v0
    return v4
}

; VCode:
; block0:
;   slli a1,a1,1
;   add a0,a1,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a1, a1, 1
;   add a0, a1, a0
;   ret

function %sh1add_uw(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 1
    v4 = ishl v2, v3
    v5 = iadd.i64 v0, v4
    return v5
}

; VCode:
; block0:
;   zext.h a2,a1
;   slli a2,a2,1
;   add a0,a0,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x3b, 0x86, 0x05, 0x08
;   slli a2, a2, 1
;   add a0, a0, a2
;   ret

function %sh2add(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 2
    v3 = ishl v1, v2
    v4 = iadd.i64 v0, v3
    return v4
}

; VCode:
; block0:
;   slli a1,a1,2
;   add a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a1, a1, 2
;   add a0, a0, a1
;   ret




function %sh2add_uw(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 2
    v4 = ishl v2, v3
    v5 = iadd.i64 v0, v4
    return v5
}

; VCode:
; block0:
;   zext.h a2,a1
;   slli a2,a2,2
;   add a0,a0,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x3b, 0x86, 0x05, 0x08
;   slli a2, a2, 2
;   add a0, a0, a2
;   ret




function %sh3add(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl v1, v2
    v4 = iadd.i64 v0, v3
    return v4
}

; VCode:
; block0:
;   slli a1,a1,3
;   add a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a1, a1, 3
;   add a0, a0, a1
;   ret

function %sh3add_uw(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 3
    v4 = ishl v2, v3
    v5 = iadd.i64 v0, v4
    return v5
}

; VCode:
; block0:
;   zext.h a2,a1
;   slli a2,a2,3
;   add a0,a0,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x3b, 0x86, 0x05, 0x08
;   slli a2, a2, 3
;   add a0, a0, a2
;   ret

